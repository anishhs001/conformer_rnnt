# -*- coding: utf-8 -*-
"""decoders.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P6Kke8MFd12X5_aJaX0sMuO3x92AvJN0
"""

import torch.nn as nn
from torch import Tensor
from typing import Tuple
import torch
import torch.nn.functional as F
#Imporved upon the code in https://github.com/sooftware/RNN-Transducer/blob/main/rnnt/decoder.py
class DecoderRNNT(nn.Module):
    """
    Decoder of RNN-Transducer
    Args:
        input_dim (int): size of input data
        hidden_dim (int, optional): hidden state dimension of decoder (default: 512)
        output_dim (int, optional): output dimension of encoder and decoder (default: 512)
        num_layers (int, optional): number of decoder layers (default: 1)
        rnn_type (str, optional): type of rnn cell (default: lstm)
        dropout_p (float, optional): dropout probability of decoder
    Inputs: inputs, input_lengths
        inputs (torch.LongTensor): A target sequence passed to decoder. `IntTensor` of size ``(batch, seq_length)``
        input_lengths (torch.LongTensor): The length of input tensor. ``(batch)``
        hidden_states (torch.FloatTensor): A previous hidden state of decoder. `FloatTensor` of size
            ``(batch, seq_length, dimension)``
    Returns:
        (Tensor, Tensor):
        * decoder_outputs (torch.FloatTensor): A output sequence of decoder. `FloatTensor` of size
            ``(batch, seq_length, dimension)``
        * hidden_states (torch.FloatTensor): A hidden state of decoder. `FloatTensor` of size
            ``(batch, seq_length, dimension)``
    """

    supported_rnns = {
        "lstm": nn.LSTM,
        "gru": nn.GRU,
        "rnn": nn.RNN,
    }

    def __init__(self, input_dim, hidden_dim, output_dim, num_layers = 4, rnn_type = "lstm", dropout_p = 0.1, enc_has_cont_val = True):
        super(DecoderRNNT, self).__init__()
        self.hidden_size = hidden_dim
        self.enc_has_cont_val = enc_has_cont_val
        if not self.enc_has_cont_val:
          self.embedding = nn.Embedding(input_dim, hidden_dim)
        rnn_cell = self.supported_rnns[rnn_type.lower()]
        self.rnn = rnn_cell(
            input_size=input_dim,
            hidden_size=hidden_dim,
            num_layers=num_layers,
            bias=True,
            batch_first=True,
            dropout=dropout_p,
            bidirectional=True
        )
        self.out_proj = nn.Linear(2 * hidden_dim, output_dim, bias = True)

    def forward(self, inputs, input_lengths = None, hidden_states = None):
        """
        Forward propage a `inputs` (targets) for training.
        Args:
            inputs (torch.LongTensor): A target sequence passed to decoder. `IntTensor` of size ``(batch, seq_length)``
            input_lengths (torch.LongTensor): The length of input tensor. ``(batch)``
            hidden_states (torch.FloatTensor): A previous hidden state of decoder. `FloatTensor` of size
                ``(batch, seq_length, dimension)``
        Returns:
            (Tensor, Tensor):
            * decoder_outputs (torch.FloatTensor): A output sequence of decoder. `FloatTensor` of size
                ``(batch, seq_length, dimension)``
            * hidden_states (torch.FloatTensor): A hidden state of decoder. `FloatTensor` of size
                ``(batch, seq_length, dimension)``
        """
        if self.enc_has_cont_val:
            embedded = inputs
        else:
            embedded = self.embedding(inputs)

        if input_lengths is not None:
            sorted_seq_lengths, indices = torch.sort(input_lengths, descending=True)
            embedded = embedded[indices]
            embedded = nn.utils.rnn.pack_padded_sequence(
                embedded.transpose(0, 1), input_lengths, enforce_sorted=False
            )
            self.rnn.flatten_parameters()
            outputs, hidden_states = self.rnn(embedded, hidden_states)
            outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)
            outputs = self.out_proj(outputs.transpose(0, 1))

        else:
            self.rnn.flatten_parameters()
            outputs, hidden_states = self.rnn(embedded, hidden_states)
            outputs = self.out_proj(outputs)

        return outputs, hidden_states